{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Multi-layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Sun Mar 30 03:19:02 2014',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'mldata_descr_ordering': array([[array(['label'], dtype='<U5'), array(['data'], dtype='<U4')]],\n",
       "       dtype=object),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'label': array([[0., 0., 0., ..., 9., 9., 9.]])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "mnist = io.loadmat('mnist-original.mat')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 70000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist['data'], mnist['label']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).T # transpose\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y).T\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 159, 253,\n",
       "       159,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238,\n",
       "       252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
       "       227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
       "        60, 224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 163, 252, 252, 252, 253, 252, 252,  96, 189, 253, 167,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  51, 238, 253, 253, 190, 114, 253, 228,  47,  79, 255,\n",
       "       168,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  48, 238, 252, 252, 179,  12,  75, 121,  21,   0,\n",
       "         0, 253, 243,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  38, 165, 253, 233, 208,  84,   0,   0,   0,\n",
       "         0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,   0,\n",
       "         0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 246, 252,\n",
       "       112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 252,\n",
       "       148,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85,\n",
       "       252, 230,  25,   0,   0,   0,   0,   0,   0,   0,   0,   7, 135,\n",
       "       253, 186,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  85, 252, 223,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "       131, 252, 225,  71,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,   0,   0,\n",
       "        48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
       "         0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,\n",
       "        85, 178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 252, 252,\n",
       "       229, 215, 252, 252, 252, 196, 130,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  28, 199,\n",
       "       252, 252, 253, 252, 252, 233, 145,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  25, 128, 252, 253, 252, 141,  37,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.plot(*args, scalex=True, scaley=True, data=None, **kwargs)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOyElEQVR4nO3df5DU9X3H8deb6wmI4EAMhBBSonKhxDQQLxgbE0ycOGBnis40JkzHEGLnMpNoMdo2ju1MnHSmQzMmNmkwKYlEzA+czKiR6VAjXplaE0M4kAiCBkOggidUsAV/4R337h/3NXPqfT+77H53v3v3fj5mbnb3+97vft+z+uK73+9nv/sxdxeA0W9M2Q0AaA7CDgRB2IEgCDsQBGEHgviDZm7sNBvr4zShmZsEQnlFL+pVP2HD1eoKu5ktkvQNSW2SvufuK1PPH6cJusAuqWeTABI2e3dureaP8WbWJmmVpMWS5kpaamZza309AI1VzzH7AklPufted39V0l2SlhTTFoCi1RP2GZKeHvL4QLbsdcysy8x6zKynTyfq2ByAejT8bLy7r3b3TnfvbNfYRm8OQI56wn5Q0swhj9+RLQPQguoJ+xZJs83sXWZ2mqRPSVpfTFsAilbz0Ju795vZNZJ+psGhtzXu/nhhnQEoVF3j7O6+QdKGgnoB0EB8XRYIgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIJo6ZTNGn/6PnZ+s934+f8qvX1+4Nrnu+x5Zlqy/fdVpyXrbpm3JejTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkTSwcH6y/s0130rWz23P/19soMK2H73w+8n6k50nk/W/mfXBCluIpa6wm9k+ScclnZTU7+6dRTQFoHhF7Nk/6u7PFfA6ABqIY3YgiHrD7pIeMLOtZtY13BPMrMvMesysp0/535MG0Fj1foy/yN0PmtlUSRvN7Al3f2joE9x9taTVkjTJpnid2wNQo7r27O5+MLs9LOleSQuKaApA8WoOu5lNMLOJr92XdKmknUU1BqBY9XyMnybpXjN77XV+7O73F9IVmqbv0vRo6d/e9oNkvaM9fU35QGI0fW9fX3Ld/xsYm6zPT5d1YvEHcmvjN+1IrjvwyivpFx+Bag67u++V9L4CewHQQAy9AUEQdiAIwg4EQdiBIAg7EASXuI4CbZMm5dZe/Mic5LpfvPXHyfpHx79QYeu17y/ueP5PkvXu2y5M1n9+8zeT9Y3f+05ube4Pr0mue/aXHknWRyL27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPso8CBO2fk1rZ8YFUTOzk1X5m6JVm//4z0OPzyfZcm62tnPZhbmzT3SHLd0Yg9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7CND/sfOT9XXz8qdNHqP0Tz1Xsnz/Jcl6z4N/lKzvuDq/t00vj0uuO7Xn5WT9qefT1+q3/+Om3NoYS646KrFnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgzN2btrFJNsUvsPS4bUQDC+cn6/+89rZk/dz22r8u8WdPXJGst/35i8n60T99d7J+5Lz8Ae2OVU8n1+1/+kCyXsm/HdyaW+s9mR7D/+yyv0rW2zZtq6mnRtvs3TrmR4d90yvu2c1sjZkdNrOdQ5ZNMbONZrYnu51cZMMAilfNx/g7JC16w7IbJXW7+2xJ3dljAC2sYtjd/SFJR9+weImktdn9tZIuL7YtAEWr9WBvmrv3ZveflTQt74lm1iWpS5LG6fQaNwegXnWfjffBM3y5Z/ncfbW7d7p7Z7vG1rs5ADWqNeyHzGy6JGW3h4trCUAj1Br29ZKWZfeXSbqvmHYANErFY3YzWyfpYklnmdkBSV+WtFLST8zsakn7JV3ZyCZHOjv/Pcn6c9enx3w72tPXpG89kV/7jxfmJtc9ctfMZP0tz6fnKT/zh79M1xO1/uSajTWtLX1IeeS6l5L1qfmXyresimF396U5Jb4dA4wgfF0WCIKwA0EQdiAIwg4EQdiBIPgp6QKMOT39NeD+rx5L1n85555k/Xf9rybr1990Q25t8n/9d3LdqRPS34c6mayOXgum70/W9zWnjUKxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnL8DLC9OXsP5sTvqnoCv5yxVfTNYn/jT/MtMyLyNFa2HPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5egD/+h+3J+pgK/6Yu35/+od7xP/3VqbYESe3WllvrqzBTeZs1byrzZmHPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5epf+96sLc2t9PuyW57oAqTLn8QHpa5XfqF8k6htfn+b96P6CB5Lr3707/N5mtbTX1VKaKe3YzW2Nmh81s55BlN5vZQTPbnv1d1tg2AdSrmo/xd0haNMzyW919Xva3odi2ABStYtjd/SFJR5vQC4AGqucE3TVm9lj2MX9y3pPMrMvMesysp08n6tgcgHrUGvZvSzpH0jxJvZK+lvdEd1/t7p3u3tmusTVuDkC9agq7ux9y95PuPiDpu5IWFNsWgKLVFHYzmz7k4RWSduY9F0BrqDjObmbrJF0s6SwzOyDpy5IuNrN5klyDU1V/rnEttob+8fm1M8ekx9EfeSV9+HL2nc+kt52sjl6V5r1/4pbzKrzC1tzKX+xdnFxzzorfJesjcd76imF396XDLL69Ab0AaCC+LgsEQdiBIAg7EARhB4Ig7EAQXOLaBEdOnpGs9+/d15xGWkylobUnV743WX9iybeS9X9/6czc2jOrzk2uO/H5/GmwRyr27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsTfDXP/9Est6RuBRzpBtYOD+3dvj6l5Pr7u5Mj6NfsuOTyfqERXtzaxM1+sbRK2HPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5eLcsvjanwb+Y3LlqXrK9SRy0dtYT9X8mfylqS7v7013NrHe3pn+B+/6+WJetvv2JXso7XY88OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzl4tzy8NaCC56sLxR5L16+44P1k/5/vp129/9nhu7dDCtybXnfLJA8n6te/sTtYXn56+Fn/9i9Nya5/esSi57ln/OiFZx6mpuGc3s5lmtsnMdpnZ42a2Ils+xcw2mtme7HZy49sFUKtqPsb3S7rB3edK+qCkL5jZXEk3Sup299mSurPHAFpUxbC7e6+7b8vuH5e0W9IMSUskrc2etlbS5Q3qEUABTumY3cxmSZovabOkae7em5WelTTswZmZdUnqkqRxSs/tBaBxqj4bb2ZnSLpb0nXufmxozd1dOaew3H21u3e6e2e7xtbVLIDaVRV2M2vXYNB/5O73ZIsPmdn0rD5d0uHGtAigCBU/xpuZSbpd0m53H3q94npJyyStzG7va0iHo8A4S7/Nuz/+nWT94Q+PS9b3nHhbbm35mfuS69ZrxTMfTtbv/8W83NrsFfF+zrlM1Ryzf0jSVZJ2mNn2bNlNGgz5T8zsakn7JV3ZkA4BFKJi2N39YeX/dMMlxbYDoFH4uiwQBGEHgiDsQBCEHQiCsANB2OCX35pjkk3xC2xknsBv6zgnt9axbn9y3X962yN1bbvST1VXusQ25dET6dde+p9dyXrH8tE73fRItNm7dcyPDjt6xp4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Lgp6SrdPI3v82t7fnErOS6c6+9NlnfdeW/1NJSVeZs+Hyy/u7bXkrWOx5lHH20YM8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0FwPTswinA9OwDCDkRB2IEgCDsQBGEHgiDsQBCEHQiiYtjNbKaZbTKzXWb2uJmtyJbfbGYHzWx79ndZ49sFUKtqfryiX9IN7r7NzCZK2mpmG7Pare5+S+PaA1CUauZn75XUm90/bma7Jc1odGMAinVKx+xmNkvSfEmbs0XXmNljZrbGzCbnrNNlZj1m1tOnE/V1C6BmVYfdzM6QdLek69z9mKRvSzpH0jwN7vm/Ntx67r7a3TvdvbNdY+vvGEBNqgq7mbVrMOg/cvd7JMndD7n7SXcfkPRdSQsa1yaAelVzNt4k3S5pt7t/fcjy6UOedoWkncW3B6Ao1ZyN/5CkqyTtMLPt2bKbJC01s3mSXNI+SZ9rQH8AClLN2fiHJQ13feyG4tsB0Ch8gw4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBEU6dsNrP/kbR/yKKzJD3XtAZOTav21qp9SfRWqyJ7+0N3f+twhaaG/U0bN+tx987SGkho1d5atS+J3mrVrN74GA8EQdiBIMoO++qSt5/Sqr21al8SvdWqKb2VeswOoHnK3rMDaBLCDgRRStjNbJGZPWlmT5nZjWX0kMfM9pnZjmwa6p6Se1ljZofNbOeQZVPMbKOZ7cluh51jr6TeWmIa78Q046W+d2VPf970Y3Yza5P0G0kfl3RA0hZJS919V1MbyWFm+yR1unvpX8Aws49IekHSne5+Xrbsq5KOuvvK7B/Kye7+pRbp7WZJL5Q9jXc2W9H0odOMS7pc0mdU4nuX6OtKNeF9K2PPvkDSU+6+191flXSXpCUl9NHy3P0hSUffsHiJpLXZ/bUa/J+l6XJ6awnu3uvu27L7xyW9Ns14qe9doq+mKCPsMyQ9PeTxAbXWfO8u6QEz22pmXWU3M4xp7t6b3X9W0rQymxlGxWm8m+kN04y3zHtXy/Tn9eIE3Ztd5O7vl7RY0heyj6styQePwVpp7LSqabybZZhpxn+vzPeu1unP61VG2A9Kmjnk8TuyZS3B3Q9mt4cl3avWm4r60Gsz6Ga3h0vu5/daaRrv4aYZVwu8d2VOf15G2LdImm1m7zKz0yR9StL6Evp4EzObkJ04kZlNkHSpWm8q6vWSlmX3l0m6r8ReXqdVpvHOm2ZcJb93pU9/7u5N/5N0mQbPyP9W0t+V0UNOX2dL+nX293jZvUlap8GPdX0aPLdxtaS3SOqWtEfSg5KmtFBvP5C0Q9JjGgzW9JJ6u0iDH9Efk7Q9+7us7Pcu0VdT3je+LgsEwQk6IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQji/wEehlE7rasv6gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "ex1 = X[0] \n",
    "ex1_image = ex1.reshape(28, 28) \n",
    "plt.imshow(ex1_image) \n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Multi-layer Neural Networks and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer neural network and backpropagation learning\n",
    "# Mini Batch Stochastic Gradient Descent\n",
    "class MLPbatch():\n",
    "    \n",
    "    def __init__(self, n_hidden=5, epochs=100, lr=0.1, batch_size=100):\n",
    "        self.n_hidden = n_hidden         # number of neurons in hidden layers\n",
    "        self.epochs = epochs             # number epochs\n",
    "        self.lr = lr                     # learning rate\n",
    "        self.batch_size = batch_size     # mini-batch size\n",
    "        \n",
    "    # sigmoid function\n",
    "    def sigmoid(self, z):\n",
    "        return (1.0 / (1.0 + np.exp(-z)))\n",
    "    \n",
    "    # change the class labels to one-hot\n",
    "    # [[0],       [[1, 0, 0, 0, 0, ...],\n",
    "    #  [2],  -->   [0, 0, 1, 0, 0, ...],\n",
    "    #  ...]        ...                 ]\n",
    "    def onehot_encoding(self, y):\n",
    "        \n",
    "        n_sample = y.shape[0]\n",
    "        n_class = np.unique(y).shape[0]\n",
    "        \n",
    "        y_enc = np.zeros((n_sample, n_class))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            y_enc[idx, val] = 1.0\n",
    "            \n",
    "        return y_enc       \n",
    "\n",
    "    # forward computation\n",
    "    # h = sigmoid(xw + b)\n",
    "    # o = sigmoid(hw + b)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        zx = np.dot(x, self.wx) + self.bx\n",
    "        h = self.sigmoid(zx)\n",
    "        \n",
    "        zh = np.dot(h, self.wh) + self.bh\n",
    "        o = self.sigmoid(zh)\n",
    "        \n",
    "        return zx, h, zh, o\n",
    "    \n",
    "    # loss = mean square error\n",
    "    def compute_loss(self, y, o):\n",
    "        \n",
    "        N = y.shape[0]\n",
    "        loss = 0.5 * np.sum((y - o)**2) / N\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    # backpropagation learning with training data\n",
    "    # initialize parameters and perform mini-batch stochastic gradient descent\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        n_sample = X_train.shape[0]             # number of taining data\n",
    "        n_feature = X_train.shape[1]            # number of features (number of inputs)\n",
    "        n_output = np.unique(y_train).shape[0]  # number of classes (number of outputs)\n",
    "        \n",
    "        # change y to one-hot encoding\n",
    "        y_train_enc = self.onehot_encoding(y_train)\n",
    "\n",
    "        # initializing parameters w and b for each layer\n",
    "        # wx: [784, n_hidden], bx: [1, n_hidden]\n",
    "        # wh: [n_hidden, 10], bx: [1, 10]\n",
    "        self.wx = np.random.normal(loc=0.0, scale=0.1, size=(n_feature, self.n_hidden))\n",
    "        self.bx = np.zeros((1, self.n_hidden))\n",
    "        \n",
    "        self.wh = np.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, n_output))\n",
    "        self.bh = np.zeros((1, n_output))\n",
    "        \n",
    "        for e in range(self.epochs):\n",
    "            \n",
    "            # update parameters for batch of sample data\n",
    "            for start_idx in range(0, n_sample-self.batch_size+1, self.batch_size):\n",
    "                \n",
    "                # x: [batch_size, 784], y: [batch_size, 10]\n",
    "                x = X_train[start_idx : start_idx + self.batch_size]\n",
    "                y = y_train_enc[start_idx : start_idx + self.batch_size]\n",
    "\n",
    "                # compute h: [batch_size, n_hidden] and o: [batch_size, 10]\n",
    "                zx, h, zh, o = self.forward(x)\n",
    "                \n",
    "                ################################################################\n",
    "                # fill your code here\n",
    "                #\n",
    "                # compute deltas and update parameters\n",
    "                # delta_o: [batch_size, 10], delta_h: [batch_size, n_hidden]\n",
    "                \n",
    "                delta_o = (y - o) * o * (1 - o)\n",
    "                delta_h = np.dot(delta_o, np.transpose(self.wh)) * h * (1-h)\n",
    "                \n",
    "                self.wh += self.lr * np.transpose(np.dot(np.transpose(delta_o), h))\n",
    "                self.bh += np.dot(np.array([self.lr] * 100), delta_o)\n",
    "                \n",
    "                self.wx += self.lr * np.transpose(np.dot(np.transpose(delta_h), x))\n",
    "                self.bx += np.dot(np.array([self.lr] * 100), delta_h)\n",
    "                \n",
    "                ################################################################\n",
    "                \n",
    "            # compute average error and accuracy for each epoch, and show\n",
    "            zx, h, zh, o = self.forward(X_train)\n",
    "            mse = self.compute_loss(y_train_enc, o) \n",
    "            \n",
    "            y_train_pred = self.predict(X_train).reshape(-1, 1)\n",
    "            train_acc = np.sum(y_train == y_train_pred) / n_sample\n",
    "            \n",
    "            print(\"Epoch %d MSE: %.2f Accuracy: %.2f\" % (e, mse, train_acc))\n",
    "        \n",
    "    # predict class of x using the learned model\n",
    "    def predict(self, x):\n",
    "        \n",
    "        zx, h, zh, o = self.forward(x)\n",
    "        y_pred = np.argmax(o, axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE: 0.86 Accuracy: 0.10\n",
      "Epoch 1 MSE: 0.82 Accuracy: 0.10\n",
      "Epoch 2 MSE: 0.75 Accuracy: 0.10\n",
      "Epoch 3 MSE: 0.69 Accuracy: 0.10\n",
      "Epoch 4 MSE: 0.65 Accuracy: 0.13\n",
      "Epoch 5 MSE: 0.63 Accuracy: 0.16\n",
      "Epoch 6 MSE: 0.61 Accuracy: 0.18\n",
      "Epoch 7 MSE: 0.59 Accuracy: 0.20\n",
      "Epoch 8 MSE: 0.57 Accuracy: 0.22\n",
      "Epoch 9 MSE: 0.56 Accuracy: 0.24\n",
      "Epoch 10 MSE: 0.54 Accuracy: 0.27\n",
      "Epoch 11 MSE: 0.53 Accuracy: 0.28\n",
      "Epoch 12 MSE: 0.53 Accuracy: 0.29\n",
      "Epoch 13 MSE: 0.53 Accuracy: 0.30\n",
      "Epoch 14 MSE: 0.52 Accuracy: 0.30\n",
      "Epoch 15 MSE: 0.52 Accuracy: 0.31\n",
      "Epoch 16 MSE: 0.52 Accuracy: 0.31\n",
      "Epoch 17 MSE: 0.51 Accuracy: 0.31\n",
      "Epoch 18 MSE: 0.51 Accuracy: 0.33\n",
      "Epoch 19 MSE: 0.50 Accuracy: 0.34\n",
      "Epoch 20 MSE: 0.49 Accuracy: 0.36\n",
      "Epoch 21 MSE: 0.48 Accuracy: 0.37\n",
      "Epoch 22 MSE: 0.47 Accuracy: 0.39\n",
      "Epoch 23 MSE: 0.46 Accuracy: 0.40\n",
      "Epoch 24 MSE: 0.46 Accuracy: 0.40\n",
      "Epoch 25 MSE: 0.46 Accuracy: 0.40\n",
      "Epoch 26 MSE: 0.45 Accuracy: 0.41\n",
      "Epoch 27 MSE: 0.44 Accuracy: 0.42\n",
      "Epoch 28 MSE: 0.43 Accuracy: 0.44\n",
      "Epoch 29 MSE: 0.42 Accuracy: 0.45\n",
      "Epoch 30 MSE: 0.41 Accuracy: 0.47\n",
      "Epoch 31 MSE: 0.40 Accuracy: 0.48\n",
      "Epoch 32 MSE: 0.40 Accuracy: 0.48\n",
      "Epoch 33 MSE: 0.40 Accuracy: 0.49\n",
      "Epoch 34 MSE: 0.39 Accuracy: 0.49\n",
      "Epoch 35 MSE: 0.39 Accuracy: 0.49\n",
      "Epoch 36 MSE: 0.39 Accuracy: 0.49\n",
      "Epoch 37 MSE: 0.39 Accuracy: 0.50\n",
      "Epoch 38 MSE: 0.38 Accuracy: 0.50\n",
      "Epoch 39 MSE: 0.38 Accuracy: 0.50\n",
      "Epoch 40 MSE: 0.39 Accuracy: 0.49\n",
      "Epoch 41 MSE: 0.40 Accuracy: 0.48\n",
      "Epoch 42 MSE: 0.40 Accuracy: 0.48\n",
      "Epoch 43 MSE: 0.39 Accuracy: 0.49\n",
      "Epoch 44 MSE: 0.39 Accuracy: 0.50\n",
      "Epoch 45 MSE: 0.38 Accuracy: 0.51\n",
      "Epoch 46 MSE: 0.38 Accuracy: 0.51\n",
      "Epoch 47 MSE: 0.37 Accuracy: 0.52\n",
      "Epoch 48 MSE: 0.37 Accuracy: 0.53\n",
      "Epoch 49 MSE: 0.36 Accuracy: 0.54\n",
      "Epoch 50 MSE: 0.36 Accuracy: 0.54\n",
      "Epoch 51 MSE: 0.36 Accuracy: 0.54\n",
      "Epoch 52 MSE: 0.36 Accuracy: 0.55\n",
      "Epoch 53 MSE: 0.36 Accuracy: 0.55\n",
      "Epoch 54 MSE: 0.35 Accuracy: 0.56\n",
      "Epoch 55 MSE: 0.34 Accuracy: 0.57\n",
      "Epoch 56 MSE: 0.34 Accuracy: 0.57\n",
      "Epoch 57 MSE: 0.33 Accuracy: 0.57\n",
      "Epoch 58 MSE: 0.33 Accuracy: 0.58\n",
      "Epoch 59 MSE: 0.32 Accuracy: 0.58\n",
      "Epoch 60 MSE: 0.31 Accuracy: 0.59\n",
      "Epoch 61 MSE: 0.31 Accuracy: 0.59\n",
      "Epoch 62 MSE: 0.30 Accuracy: 0.60\n",
      "Epoch 63 MSE: 0.30 Accuracy: 0.60\n",
      "Epoch 64 MSE: 0.30 Accuracy: 0.60\n",
      "Epoch 65 MSE: 0.30 Accuracy: 0.60\n",
      "Epoch 66 MSE: 0.31 Accuracy: 0.60\n",
      "Epoch 67 MSE: 0.32 Accuracy: 0.59\n",
      "Epoch 68 MSE: 0.32 Accuracy: 0.58\n",
      "Epoch 69 MSE: 0.32 Accuracy: 0.58\n",
      "Epoch 70 MSE: 0.32 Accuracy: 0.58\n",
      "Epoch 71 MSE: 0.32 Accuracy: 0.58\n",
      "Epoch 72 MSE: 0.31 Accuracy: 0.59\n",
      "Epoch 73 MSE: 0.31 Accuracy: 0.60\n",
      "Epoch 74 MSE: 0.30 Accuracy: 0.61\n",
      "Epoch 75 MSE: 0.30 Accuracy: 0.62\n",
      "Epoch 76 MSE: 0.29 Accuracy: 0.62\n",
      "Epoch 77 MSE: 0.29 Accuracy: 0.63\n",
      "Epoch 78 MSE: 0.29 Accuracy: 0.63\n",
      "Epoch 79 MSE: 0.28 Accuracy: 0.64\n",
      "Epoch 80 MSE: 0.28 Accuracy: 0.64\n",
      "Epoch 81 MSE: 0.28 Accuracy: 0.65\n",
      "Epoch 82 MSE: 0.28 Accuracy: 0.65\n",
      "Epoch 83 MSE: 0.27 Accuracy: 0.65\n",
      "Epoch 84 MSE: 0.27 Accuracy: 0.66\n",
      "Epoch 85 MSE: 0.27 Accuracy: 0.66\n",
      "Epoch 86 MSE: 0.27 Accuracy: 0.66\n",
      "Epoch 87 MSE: 0.26 Accuracy: 0.67\n",
      "Epoch 88 MSE: 0.26 Accuracy: 0.67\n",
      "Epoch 89 MSE: 0.26 Accuracy: 0.67\n",
      "Epoch 90 MSE: 0.26 Accuracy: 0.67\n",
      "Epoch 91 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 92 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 93 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 94 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 95 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 96 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 97 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 98 MSE: 0.25 Accuracy: 0.68\n",
      "Epoch 99 MSE: 0.25 Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# create the model with hidden layer neuron 50, epochs 100, learning rate 0.01, batch size 100\n",
    "model = MLPbatch(n_hidden=50, epochs=100, lr=0.01, batch_size=100)\n",
    "\n",
    "# backpropagation learning with the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.plot(*args, scalex=True, scaley=True, data=None, **kwargs)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "ex1 = X[35000] \n",
    "ex1_image = ex1.reshape(28, 28) \n",
    "plt.imshow(ex1_image) \n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([ex1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.plot(*args, scalex=True, scaley=True, data=None, **kwargs)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "ex2 = X[50000] \n",
    "ex2_image = ex2.reshape(28, 28) \n",
    "plt.imshow(ex2_image) \n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([ex2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
